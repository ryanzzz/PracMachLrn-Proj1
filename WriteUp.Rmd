---
title: "Practice Machine learning Write Up Project"
date:  "`r Sys.Date()`"
---

```{r, echo=FALSE}
library(knitr)
```

## Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

## Libraries

Below libraries are used in the data analysis and write up.

```{r, results="hide", message=FALSE}
library(caret)
library(randomForest)
library(rpart)
```

## Data Pre-processing

The training data for this project are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
The test data are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

First of all, we want to download the two csv files, store them into a local folder called "data", and load the data sets into the R Studio environment as two dataframes. To avoid downloading data from the internet every time, the codes will try to find the "data" folder, and assume data sets have been downloaded and R Studio memory loaded. 

```{r, cache=TRUE}
if (!file.exists("data")) {
    dir.create("data")

    fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    destfile <- "./data/pml-training.csv"
    download.file(fileUrl, destfile=destfile, method="curl", quiet=TRUE)
    trainingset <- read.csv(destfile, na.strings=c("NA","#DIV/0!", ""))
    
    fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    destfile <- "./data/pml-testing.csv"
    download.file(fileUrl, destfile=destfile, method="curl", quiet=TRUE)
    testingset <- read.csv(destfile, na.strings=c("NA","#DIV/0!", ""))
}
```

Remove the rows that have any column containing "NA" to clean the two data sets.

```{r, cache=TRUE}
trainingset<-trainingset[,colSums(is.na(trainingset)) == 0]
testingset <-testingset[,colSums(is.na(testingset)) == 0]
```

Before jumping into any data operation, it is always helpful to explore the raw data sets a little bit through `summary(trainingset)` or `head(trainingset)` commands. We removed the first 7 columns that contain irrelevant information like username or timestamps after some preliminary observation.

```{r, cache=TRUE}
trainingset   <-trainingset[,-c(1:7)]
testingset <-testingset[,-c(1:7)]
```

## Data Partitioning

The downloaded testing data is for prediction in the future. No matter what machine learning algorithm is going to be applied, we will need to construct a new testing data set out of the original training data set for cross-validation against our model. We chose to partition the training data set into 2 sub-sets: subTraining (70%) and subTest (30%). This will be performed using random subsampling without replacement.

```{r, cache=TRUE}
subsamples <- createDataPartition(y=trainingset$classe, p=0.7, list=FALSE)
subTraining <- trainingset[subsamples, ] 
subTesting <- trainingset[-subsamples, ]
```

## Statistic Modeling

Multiple machine learning algorithms were tried but due to the page limit we only inlcuded one of them here for project presentation. *Random Forest* method was chosen for modeling.

```{r, cache=TRUE}
model <- randomForest(classe ~ ., data=subTraining, method="class")
val <- predict(model, subTesting, type = "class")
print(confusionMatrix(val, subTesting$classe))
```

Accuracy for Random Forest model was 0.995 with a 95% CI in (0.993, 0.997). The sensitivity, specificity and balanced accurary are all around 0.99 or higher across all 5 classes. With such a high accurary on our cross-validation data, we can expect that very few, or none, of the test samples will be missclassified. 

## Prediction with the Testing Data

We applied the R.F. model to the testing data set.

```{r, cache=TRUE}
pred <- predict(model, testingset, type = "class")
pred
```

The output was saved to a txt file according to instructions and uploaded to the same folder as this write-up.
